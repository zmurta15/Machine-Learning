Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. In case of doubt, you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.
- You can include references to images or html files such as the reports generated with clusters. To do this, simply include this document in the folder with the reports or images and refer them in the text by the file name in an isolated line. For example, the line

test.png

refers to a test.png image file in the same folder as this document.

QUESTIONS:


Q1: After extracting the attributes, did you standardize or normalize the values? Justify your decision.
R1: We decided to standardize our data after the extraction of the features, since 3 different extraction tecnhiques were used
and we wanted to make sure that every feature extracted is scaled, having zero mean and unit variance, and this way we are able 
to ensure that all features are on a similar scale and have equal influence on the feature extraction process.


Q2: Explain how you found the parameters for the clustering algorithms.
R2: The three clustering algorithms used only have one parameter, the number of clusters to divide the data into. This is an 
assumptiom before actually running the algorithms, so we need to analyse the data produced by the internal and external indexes.
To produce a detailed analysis of these indexes with a k number of clusters, we iterated through a reasonable number of clusters (we chose 10)
and ploted the results of each index for each number k of clusters. This way we were able to identify what were the best number 
of clusters to produce. Using the "report_clusters" function, we displayed the images that are part of each cluster, for each k
number of cluster, to help us choose the best numbers of clusters. The indexes ploted are available to visualize inf image 
"indexes.png".


Q3: Describe your analysis of the parameters using the internal and external indicators referred in the assignment page. Include the  plots for the indicator values ​​(indicating the image name of each plot in one line in your answer) as a function of the parameters and explain how you chose the ranges for examining these parameters. Indicate, with justification, what conclusions you can draw from this analysis.
R3: To analyse we used the produced external and internal indexes that are available on images "indexes.png" and "kmeansloss.png". The interval used for the internal and external indexes was from 2 to 10 clusters, 
because we think that more than 10 would not make sense, considering that we want to separate different stages of the lifecycle of cells, which is typically divided into 7 stages. 
From the analysis of the indexes, mainly the k-means loss, purity, and precision of the clusters we can conclude that an interval with good and interesting results would be around 6 to 10 clusters. To choose the k-means loss we used the elbow method.
For the external indexes we calculated a average of benefit for each one, this is, we wanted a number of clusters that showed a high precison and purity but a lower recall.
"indexes.png"
"kmeansloss.png"

Q4: Select some of the parameter values ​​tested in the question above and examine the corresponding clusters more closely, generating the HTML file with the images. Explain how you selected these parameter values, discuss the different options and propose a recommendation that could help the biologists' task of classifying cells and rejecting segmentation errors.
R4: The cluster number choosen can obviously be different for each clustering algorithm but we chose to show with 6 clusters because it agrees with the methods previooulsy mentioned in the question above and after html analysis it shows a very good distinction of the cells' images.
As mentioned in the question above, other value withing the range from 6 to 10 number of clusters would also suit our implementation. This way, we can conclude that the number of clusters that we chose, can help the scientists by reveling that more than just 3 classification labels for the cell's lifecycle woul probably be a better option.
In the generated HTML files we are also able to identify the cells with segmentation erros, that are mainly organized in the same cluster. This helps the scientists because they can reject the images that belong to this cluster.


Q5: Discuss advantages or problems with the algorithms analysed for the purpose of helping biologists to organize these images, considering your theoretical knowledge of these algorithms as well as the results you obtained in your work.
R5: One big disadvantage that we have is that the number of samples that are labelled by the scientists are low. This can make our evaluation of the external indexes not as accurate, because a proportion of 81 samples labelled to the total of 563 images may not be suitable to describe all samples.
Another disadvantage of our implementation, is that, in all our clustering algorithms we have to choose the number of clusters that we want to cluster the data to.
The use of 3 different clustering algorithms is an advantage in our work, because each one has a different main strength. The k-means clustering algorithm is recommended for linear data and globular clusters, the agglomerative clustering 
algorithm helps to find a structure in the provided data, and spectral clustering can be important for different shaped clusters. All these algorithms are equally important since we do not know the structure of our data, neither the number of clusters or shape it has.


Q6: Consider other clustering algorithms embedded in the Scikit-Learn library. Choose one and apply it to this problem, optimizing the parameters you deem appropriate in the way that you find adequate. Justify your choices and discuss whether this option would yield more useful results for biologists.
R6: We decided to implement the DBSCAN clustering algorithm because it has different advantages when compared wiht the other used and can help the biologists to reach more conclusions. 
This implementation is done in the end of the script. DBSCAN is a density based clustering algorithm and has two important parameters that need to be optimized in order to reach a optimal
clustering. We choose to use conclusions made in some research papers, for the min Points that need to be in the epsilon distance for the point to not be considered noise we used the dimensions
of the data multiplied by 2 and for epsilon value we used KNN neighbours method where we plot the KNN-plot using k qual to min points and choose
for the value of eps where the curve has the largest curvature. This took the values to be eps equal to 0.8 and min Points equal to 8.
The biggest advantages that the biologists can have with this method is that there is no need to explicit the number of clusters so the algorithm will
fit to the data according to the given parameters and some points will be considered noise, giving the oppurtunity to reject some samples in the data set.
"DBSCAN_eps.png"

(Optional) Q7: Explain how you selected the best attributes for the clustering phase. In particular, indicate the visualization methods used to explore the extracted attributes and any statistical tests used.
R7: To be able to perform the clustering algortihms with the best features available of the data, we started using the SelectKBest function from the sklearn library to select the features that have the highest scores
using f_classif function as a parameter to compute the ANOVA F-value between the features. This plot is available in the "bars.png" image. We decided to keep the 5 features with the highest scores.
After this, we decided to display a scatter matrix of these 5 features to check if any of the features are related. As it is presennted in image "scattermatrix.png", we discovered that 2 of the features are very correlated to each other,
so we chose to mannualy remove one of them, remaing with 4 features for our clustering algorithms. (In the scatter matrix plot it is also possible to observe the histograms of each of the 5 best features mentioned earlier.)


(Optional) Q8: Implement the Bissecting K-Means hierarchical clustering algorithm as described in the assignment page and Lecture 19. Examine and discuss the results and their application to the problem of helping the biologists select and classify cell images.
R8:

